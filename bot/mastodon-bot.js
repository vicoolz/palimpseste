/**
 * Bot Mastodon ‚Äî Palimpseste
 * 
 * Poste automatiquement des extraits litt√©raires.
 * Source primaire : tendances Supabase (extraits cur√©s par les utilisateurs).
 * Fallback : r√©cup√©ration live depuis Wikisource.
 * Ex√©cut√© via GitHub Actions (1x/heure, 24h/24, audience internationale).
 * 
 * N√©cessite les variables d'environnement :
 *   MASTODON_INSTANCE        (ex: mastodon.social, piaille.fr)
 *   MASTODON_ACCESS_TOKEN    (token d'acc√®s g√©n√©r√© dans Pr√©f√©rences > D√©veloppement)
 *   SUPABASE_SERVICE_ROLE_KEY (cl√© service_role pour √©crire dans la base, bypass RLS)
 */

const https = require('https');

// ‚îÄ‚îÄ‚îÄ Wikisource Config (identique √† l'app sources.js) ‚îÄ‚îÄ‚îÄ

const WIKISOURCES = [
    // Langues modernes
    { lang: 'fr', url: 'https://fr.wikisource.org' },
    { lang: 'en', url: 'https://en.wikisource.org' },
    { lang: 'de', url: 'https://de.wikisource.org' },
    { lang: 'it', url: 'https://it.wikisource.org' },
    { lang: 'es', url: 'https://es.wikisource.org' },
    { lang: 'pt', url: 'https://pt.wikisource.org' },
    { lang: 'ru', url: 'https://ru.wikisource.org' },
    { lang: 'zh', url: 'https://zh.wikisource.org' },
    { lang: 'ja', url: 'https://ja.wikisource.org' },
    { lang: 'ar', url: 'https://ar.wikisource.org' },
    { lang: 'el', url: 'https://el.wikisource.org' },
    // Langues anciennes
    { lang: 'la', url: 'https://la.wikisource.org' },
    { lang: 'he', url: 'https://he.wikisource.org' },
    { lang: 'sa', url: 'https://sa.wikisource.org' },
    { lang: 'yi', url: 'https://yi.wikisource.org' },
];

// Mots-cl√©s de recherche par langue (identique √† l'app)
const SEARCH_TERMS = {
    fr: ['Po√©sie', 'Roman', 'Conte', 'Th√©√¢tre', 'Philosophie', 'Lettres', 'Histoire'],
    en: ['Poetry', 'Novel', 'Tale', 'Play', 'Philosophy', 'Letters', 'History'],
    de: ['Gedicht', 'Roman', 'M√§rchen', 'Theater', 'Philosophie'],
    it: ['Poesia', 'Romanzo', 'Favola', 'Teatro'],
    es: ['Poes√≠a', 'Novela', 'Cuento', 'Teatro'],
    pt: ['Poesia', 'Romance', 'Conto', 'Teatro'],
    ru: ['–ø–æ—ç–∑–∏—è', '—Ä–æ–º–∞–Ω', '—Å–∫–∞–∑–∫–∞', '—Ç–µ–∞—Ç—Ä', '—Ñ–∏–ª–æ—Å–æ—Ñ–∏—è'],
    zh: ['Ë©©', 'Â∞èË™™', 'Êà≤Âäá', 'Âì≤Â≠∏'],
    ja: ['Ë©©', 'Â∞èË™¨', 'ÊàØÊõ≤', 'Áâ©Ë™û'],
    ar: ['ÿ¥ÿπÿ±', 'ÿ±ŸàÿßŸäÿ©', 'ŸÇÿµÿ©', 'ŸÖÿ≥ÿ±ÿ≠'],
    el: ['œÄŒøŒØŒ∑œÉŒ∑', 'ŒºœÖŒ∏ŒπœÉœÑœåœÅŒ∑ŒºŒ±', 'Œ∏Œ≠Œ±œÑœÅŒø', 'œÜŒπŒªŒøœÉŒøœÜŒØŒ±'],
    la: ['carmen', 'ode', 'epistula', 'liber', 'fabula', 'poema', 'oratio'],
    he: ['◊©◊ô◊®', '◊™◊î◊ú◊ô◊ù', '◊û◊©◊ú', '◊°◊§◊®', '◊ì◊ë◊®'],
    sa: ['‡§ó‡•Ä‡§§‡§æ', '‡§∂‡•ç‡§≤‡•ã‡§ï', '‡§∏‡•Ç‡§ï‡•ç‡§§', '‡§ï‡§•‡§æ', '‡§∏‡•ç‡§§‡•ã‡§§‡•ç‡§∞'],
    yi: [],
};

const LANG_WEIGHTS = { fr: 5, en: 3, de: 1, it: 1, es: 1, pt: 1, ru: 1, zh: 1, ja: 1, ar: 1, el: 1, la: 1, he: 1, sa: 1, yi: 1 };

// ‚îÄ‚îÄ‚îÄ HTTP Helpers ‚îÄ‚îÄ‚îÄ

function httpGet(url) {
    return new Promise((resolve, reject) => {
        https.get(url, { headers: { 'User-Agent': 'PalimpsestBot/1.0 (https://palimpseste.vercel.app)' } }, (res) => {
            let data = '';
            res.on('data', chunk => data += chunk);
            res.on('end', () => {
                try {
                    // Handle non-JSON responses (HTML error pages, 404s, etc.)
                    if (res.statusCode < 200 || res.statusCode >= 300) {
                        reject(new Error(`HTTP ${res.statusCode} for ${url}`));
                        return;
                    }
                    resolve(JSON.parse(data));
                }
                catch (e) { reject(new Error(`JSON parse error for ${url}: ${e.message}`)); }
            });
        }).on('error', reject);
    });
}

function httpRequest(options, body) {
    return new Promise((resolve, reject) => {
        const req = https.request(options, (res) => {
            let data = '';
            res.on('data', chunk => data += chunk);
            res.on('end', () => {
                try {
                    const parsed = JSON.parse(data);
                    if (res.statusCode >= 200 && res.statusCode < 300) resolve(parsed);
                    else reject(new Error(`Mastodon API ${res.statusCode}: ${JSON.stringify(parsed)}`));
                } catch (e) {
                    reject(new Error(`Mastodon API ${res.statusCode}: ${data}`));
                }
            });
        });
        req.on('error', reject);
        if (body) req.write(body);
        req.end();
    });
}

// ‚îÄ‚îÄ‚îÄ Supabase Trending Config ‚îÄ‚îÄ‚îÄ

const SUPABASE_URL = 'https://cqoepdrqifilqxnvflyy.supabase.co';
const SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNxb2VwZHJxaWZpbHF4bnZmbHl5Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjkxNzQxMTksImV4cCI6MjA4NDc1MDExOX0.e7dJmzUEgzDIix12ca38HvBmF7Cgp_fTZPT6gZ6Xy5s';

/**
 * Fetch trending extraits from Supabase (the app's user-curated content).
 * Returns a quote object { text, author, source, lang } or null.
 */
async function fetchTrendingQuote(forceLang, excludeUrls = new Set()) {
    try {
        const query = new URLSearchParams({
            select: 'id,texte,source_title,source_author,source_url,likes_count',
            order: 'likes_count.desc,created_at.desc',
            limit: '100',
            'or': '(is_silent.is.null,is_silent.eq.false)',
            'source_author': 'not.is.null',
            'texte': 'not.is.null',
        });

        const url = `${SUPABASE_URL}/rest/v1/extraits?${query.toString()}`;

        const data = await new Promise((resolve, reject) => {
            https.get(url, {
                headers: {
                    'apikey': SUPABASE_ANON_KEY,
                    'Authorization': `Bearer ${SUPABASE_ANON_KEY}`,
                    'Accept': 'application/json',
                    'User-Agent': 'PalimpsestBot/1.0',
                }
            }, (res) => {
                let body = '';
                res.on('data', chunk => body += chunk);
                res.on('end', () => {
                    try {
                        const parsed = JSON.parse(body);
                        if (res.statusCode >= 200 && res.statusCode < 300) resolve(parsed);
                        else reject(new Error(`Supabase ${res.statusCode}: ${body}`));
                    } catch (e) { reject(new Error(`Supabase JSON parse: ${e.message}`)); }
                });
            }).on('error', reject);
        });

        if (!Array.isArray(data) || data.length === 0) {
            console.log('   No trending extraits found in Supabase');
            return null;
        }

        console.log(`   Found ${data.length} trending extraits in Supabase`);

        // Filter: need texte >= 30 chars, real author, not junk content, not already posted
        const valid = data.filter(e =>
            e.texte && e.texte.trim().length >= 30 &&
            e.source_author && e.source_author.trim().length > 1 &&
            isQuotePostWorthy(e.texte, e.source_author) &&
            !excludeUrls.has(e.source_url)
        );

        if (valid.length === 0) {
            console.log('   No valid extraits after filtering');
            return null;
        }

        const pool = [];
        valid.forEach((e, i) => {
            const weight = i < 5 ? 3 : i < 15 ? 2 : 1;
            for (let w = 0; w < weight; w++) pool.push(e);
        });
        const pick = pool[Math.floor(Math.random() * pool.length)];

        let lang = forceLang || 'fr';
        if (pick.source_url) {
            if (pick.source_url.includes('fr.wikisource') || pick.source_url.includes('/fr/')) lang = 'fr';
            else if (pick.source_url.includes('en.wikisource') || pick.source_url.includes('/en/')) lang = 'en';
            else if (pick.source_url.includes('de.wikisource')) lang = 'de';
            else if (pick.source_url.includes('it.wikisource')) lang = 'it';
            else if (pick.source_url.includes('es.wikisource')) lang = 'es';
            else if (pick.source_url.includes('la.wikisource')) lang = 'la';
        }

        if (forceLang && lang !== forceLang) {
            console.log(`   Picked extrait is ${lang} but need ${forceLang}, trying another‚Ä¶`);
            const langMatches = valid.filter(e => {
                if (!e.source_url) return forceLang === 'fr';
                if (e.source_url.includes(`${forceLang}.wikisource`)) return true;
                if (e.source_url.includes(`/${forceLang}/`)) return true;
                return false;
            });
            if (langMatches.length === 0) {
                console.log(`   No trending extraits for lang=${forceLang}`);
                return null;
            }
            const langPick = langMatches[Math.floor(Math.random() * langMatches.length)];
            return {
                text: langPick.texte.trim(),
                author: langPick.source_author.trim(),
                source: langPick.source_url || `${langPick.source_title}`,
                lang: forceLang,
                fromTrending: true,
                extraitId: langPick.id || null,
            };
        }

        return {
            text: pick.texte.trim(),
            author: pick.source_author.trim(),
            source: pick.source_url || `${pick.source_title}`,
            lang,
            fromTrending: true,
            extraitId: pick.id || null,
        };

    } catch (err) {
        console.log(`   ‚ö†Ô∏è Supabase trending fetch failed: ${err.message}`);
        return null;
    }
}

// ‚îÄ‚îÄ‚îÄ Supabase Insert (sauvegarde des extraits Wikisource) ‚îÄ‚îÄ‚îÄ

// UUID fixe pour le compte bot (cr√©√© automatiquement dans auth.users)
const BOT_USER_ID = '00000000-0000-4000-a000-b07b07b07b07';
const BOT_EMAIL = 'bot@palimpseste.app';

/**
 * Cr√©e le compte bot dans auth.users s'il n'existe pas encore.
 * Utilise l'API Admin Auth de Supabase (service_role key).
 * Idempotent : si le user existe d√©j√† (422), on ignore l'erreur.
 */
async function ensureBotUserExists(serviceRoleKey) {
    try {
        const body = JSON.stringify({
            id: BOT_USER_ID,
            email: BOT_EMAIL,
            password: `bot-${Date.now()}-notrealpassword`,
            email_confirm: true,
        });
        const url = new URL(`${SUPABASE_URL}/auth/v1/admin/users`);
        await new Promise((resolve, reject) => {
            const options = {
                hostname: url.hostname,
                path: url.pathname,
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Content-Length': Buffer.byteLength(body),
                    'apikey': serviceRoleKey,
                    'Authorization': `Bearer ${serviceRoleKey}`,
                }
            };
            const req = https.request(options, (res) => {
                let responseBody = '';
                res.on('data', chunk => responseBody += chunk);
                res.on('end', () => {
                    // 200/201 = created, 422 = already exists ‚Äî both OK
                    if (res.statusCode < 500) resolve();
                    else reject(new Error(`Auth Admin ${res.statusCode}: ${responseBody}`));
                });
            });
            req.on('error', reject);
            req.write(body);
            req.end();
        });
    } catch (err) {
        console.log(`   ‚ö†Ô∏è Bot user check failed: ${err.message} (non-fatal)`);
    }
}

/**
 * Sauvegarde un extrait Wikisource dans Supabase avant de le poster.
 * Utilise la cl√© service_role pour bypasser RLS (pas d'auth.uid()).
 * L'extrait est marqu√© is_silent=true pour le nettoyage TTL.
 * Retourne l'UUID de l'extrait cr√©√©, ou null en cas d'erreur.
 */
async function saveExtraitToSupabase(quote) {
    const serviceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY;
    if (!serviceRoleKey) {
        console.log('   ‚ö†Ô∏è SUPABASE_SERVICE_ROLE_KEY not set, skipping save');
        return null;
    }

    try {
        // S'assurer que le compte bot existe dans auth.users (FK constraint)
        await ensureBotUserExists(serviceRoleKey);

        const texte = (quote.text || '').substring(0, 150).trim();
        const body = JSON.stringify({
            user_id: BOT_USER_ID,
            texte,
            source_title: quote.title || quote.author || 'Wikisource',
            source_author: quote.author || 'Anonyme',
            source_url: quote.source || null,
            is_silent: true,
            likes_count: 0,
            comments_count: 0,
        });

        const url = new URL(`${SUPABASE_URL}/rest/v1/extraits`);

        const data = await new Promise((resolve, reject) => {
            const options = {
                hostname: url.hostname,
                path: url.pathname,
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Content-Length': Buffer.byteLength(body),
                    'apikey': serviceRoleKey,
                    'Authorization': `Bearer ${serviceRoleKey}`,
                    'Prefer': 'return=representation',
                    'Accept': 'application/json',
                }
            };
            const req = https.request(options, (res) => {
                let responseBody = '';
                res.on('data', chunk => responseBody += chunk);
                res.on('end', () => {
                    try {
                        const parsed = JSON.parse(responseBody);
                        if (res.statusCode >= 200 && res.statusCode < 300) resolve(parsed);
                        else reject(new Error(`Supabase INSERT ${res.statusCode}: ${responseBody}`));
                    } catch (e) { reject(new Error(`Supabase INSERT parse: ${e.message}`)); }
                });
            });
            req.on('error', reject);
            req.write(body);
            req.end();
        });

        // Supabase REST retourne un tableau avec l'objet ins√©r√©
        const inserted = Array.isArray(data) ? data[0] : data;
        if (inserted?.id) {
            console.log(`   üíæ Saved to Supabase: ${inserted.id} (is_silent=true)`);
            return inserted.id;
        }
        console.log('   ‚ö†Ô∏è Supabase INSERT returned no id');
        return null;

    } catch (err) {
        console.log(`   ‚ö†Ô∏è Supabase save failed: ${err.message}`);
        return null;
    }
}

// ‚îÄ‚îÄ‚îÄ D√©duplication : historique des posts du bot ‚îÄ‚îÄ‚îÄ

/**
 * R√©cup√®re les source_url des extraits d√©j√† post√©s par le bot.
 * Utilis√© pour √©viter de reposter le m√™me contenu.
 * Retourne un Set de source_url.
 */
async function fetchRecentBotPosts() {
    try {
        const query = new URLSearchParams({
            select: 'source_url',
            user_id: `eq.${BOT_USER_ID}`,
            'source_url': 'not.is.null',
            order: 'created_at.desc',
            limit: '1000',
        });
        const url = `${SUPABASE_URL}/rest/v1/extraits?${query.toString()}`;

        const data = await new Promise((resolve, reject) => {
            https.get(url, {
                headers: {
                    'apikey': SUPABASE_ANON_KEY,
                    'Authorization': `Bearer ${SUPABASE_ANON_KEY}`,
                    'Accept': 'application/json',
                    'User-Agent': 'PalimpsestBot/1.0',
                }
            }, (res) => {
                let body = '';
                res.on('data', chunk => body += chunk);
                res.on('end', () => {
                    try {
                        const parsed = JSON.parse(body);
                        if (res.statusCode >= 200 && res.statusCode < 300) resolve(parsed);
                        else resolve([]);
                    } catch (e) { resolve([]); }
                });
            }).on('error', () => resolve([]));
        });

        const urls = new Set(data.filter(e => e.source_url).map(e => e.source_url));
        console.log(`   üìã Bot history: ${urls.size} previously posted URLs`);
        return urls;
    } catch (err) {
        console.log(`   ‚ö†Ô∏è Could not fetch bot history: ${err.message}`);
        return new Set();
    }
}

// ‚îÄ‚îÄ‚îÄ Universal Post Quality Gate ‚îÄ‚îÄ‚îÄ

function isQuotePostWorthy(text, author) {
    if (!text || !author) return false;
    const t = text.trim();
    const a = author.trim().toLowerCase();

    if (/public domain|domaine public|united states|federal government|17\s*U\.?S\.?C/i.test(t)) return false;
    if (/copyright|¬©|all rights reserved|creative commons|free documentation license/i.test(t)) return false;
    if (/this work is (in the |)public domain/i.test(t)) return false;

    if (/encyclop[a√¶]edia|encyclop√©die|dictionnaire|dictionary|w√∂rterbuch/i.test(a)) return false;
    if (/^\d{4}\s/i.test(a)) return false;
    if (/wikisource|wikipedia|wiki/i.test(a)) return false;

    const upper = (t.match(/[A-Z√Ä-√ú]/g) || []).length;
    const lower = (t.match(/[a-z√†-√º]/g) || []).length;
    if (upper + lower > 20 && upper / (upper + lower) > 0.55) return false;

    const words = t.split(/\s+/);
    const capsWords = words.filter(w => w.length > 2 && w === w.toUpperCase() && /[A-Z√Ä-√ú]/.test(w));
    if (words.length > 5 && capsWords.length / words.length > 0.3) return false;

    if (/\b(libraire|imprimeur|√©diteur|typograph|imprimerie|chez\s[A-Z])\b/i.test(t) &&
        /\bPARIS\b|\bLONDON\b|\bLYON\b|\bBRUXELLES\b/.test(t)) return false;

    if (t.length < 40) return false;

    if (/\uFFFD|√Ø¬ø¬Ω|√É¬©|√É¬®|√É |√¢‚Ç¨‚Ñ¢|√¢‚Ç¨≈ì/.test(t)) return false;

    const lines = t.split('\n').filter(l => l.trim().length > 0);
    if (lines.length > 3 && t.length / lines.length < 30) return false;

    if (/^(AUGMENT[√âE]|NOUVELLE [√âE]DITION|PREMI[√àE]RE PARTIE|TOME [IVXLCDM]+|VOL\.?\s)/i.test(t.trim())) return false;
    if (/^(FABLES|TABLE DES|SOMMAIRE|CONTENTS|PR√âFACE|PREFACE|INTRODUCTION)\b/i.test(t.trim())) return false;

    return true;
}

// ‚îÄ‚îÄ‚îÄ Wikisource Fetching ‚îÄ‚îÄ‚îÄ

function pickWeightedLang(forceLang) {
    if (forceLang) {
        const ws = WIKISOURCES.find(w => w.lang === forceLang);
        if (ws) return ws;
    }
    const pool = [];
    for (const ws of WIKISOURCES) {
        const w = LANG_WEIGHTS[ws.lang] || 1;
        for (let i = 0; i < w; i++) pool.push(ws);
    }
    return pool[Math.floor(Math.random() * pool.length)];
}

async function searchWikisource(ws) {
    const terms = SEARCH_TERMS[ws.lang] || SEARCH_TERMS['fr'];
    if (terms.length === 0) return getRandomPages(ws);
    const term = terms[Math.floor(Math.random() * terms.length)];
    const offset = Math.floor(Math.random() * 50);
    const url = `${ws.url}/w/api.php?action=query&list=search&srsearch=${encodeURIComponent(term)}&srlimit=20&sroffset=${offset}&srnamespace=0&format=json&origin=*`;
    const data = await httpGet(url);
    return data?.query?.search || [];
}

async function getRandomPages(ws) {
    const url = `${ws.url}/w/api.php?action=query&list=random&rnnamespace=0&rnlimit=5&format=json&origin=*`;
    const data = await httpGet(url);
    return data?.query?.random || [];
}

async function parsePage(ws, title) {
    const url = `${ws.url}/w/api.php?action=parse&page=${encodeURIComponent(title)}&prop=text|displaytitle|categories|links&pllimit=500&format=json&origin=*&redirects=true`;
    const data = await httpGet(url);
    return data?.parse || null;
}

function extractText(html) {
    if (!html) return '';

    let content = html;
    const prpMatch = html.match(/<div[^>]*class="[^"]*prp-pages-output[^"]*"[^>]*>([\s\S]*?)<\/div>\s*(?:<div|$)/i);
    const poemMatch = html.match(/<div[^>]*class="[^"]*poem[^"]*"[^>]*>([\s\S]*?)<\/div>/i);
    const mwMatch = html.match(/<div[^>]*class="[^"]*mw-parser-output[^"]*"[^>]*>([\s\S]*)/i);
    if (prpMatch) content = prpMatch[1];
    else if (poemMatch) content = poemMatch[1];
    else if (mwMatch) content = mwMatch[1];

    let text = content
        .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
        .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
        .replace(/<(sup|sub)[^>]*>[\s\S]*?<\/\1>/gi, '')
        .replace(/<span[^>]*class="[^"]*reference[^"]*"[^>]*>[\s\S]*?<\/span>/gi, '')
        .replace(/<(div|table|ul|section|nav|aside|span)[^>]*class="[^"]*(?:ws-noexport|noprint|navbox|infobox|metadata|hatnote|ambox|toc|catlinks|mw-editsection|headertemplate|ws-header|header|homonymie|bandeau-homonymie|bandeau-portail|titreoeuvre|auteur-oeuvre|redirectMsg|mw-headline|mw-page-title)[^"]*"[^>]*>[\s\S]*?<\/\1>/gi, '')
        .replace(/<span[^>]*class="[^"]*(?:page-title|mw-page-title|mw-[a-z]+|ws-[a-z]+)[^"]*"[^>]*>[\s\S]*?<\/span>/gi, '')
        .replace(/<[^>]+>/g, '')
        .replace(/&nbsp;/g, ' ')
        .replace(/&amp;/g, '&')
        .replace(/&lt;/g, '<')
        .replace(/&gt;/g, '>')
        .replace(/&#\d+;/g, '')
        .replace(/&[a-z]+;/g, '')
        .replace(/\[modifier[^\]]*\]/g, '')
        .replace(/\[\d+\]/g, '')
        .replace(/modifier le wikicode/gi, '')
        .replace(/mw-page-title[^\s]*/gi, '')
        .replace(/Po√©sies \([^)]+\)/g, '')
        .replace(/^\d{2,5}\s*/gm, '')
        .replace(/^\s*[IVXLCDM]{1,10}\s*$/gm, '')
        .replace(/^(?:CHAPTER|CHAPITRE|CANTO|LIVRE|BOOK)\s+[IVXLCDM\d]+\s*/gim, '')
        .replace(/^[IVXLCDM]{2,10}\s+/gm, '')
        .replace(/\n{3,}/g, '\n\n')
        .trim();

    const lines = text.split('\n');
    let start = 0;
    for (let i = 0; i < Math.min(15, lines.length); i++) {
        const l = lines[i].toLowerCase();
        const line = lines[i].trim();
        if (l.includes('sommaire') || l.includes('√©dition') || l.includes('navigation') ||
            l.includes('conf√©rence') || l.includes('pr√©sent√©') || l.includes('si√®ge') ||
            l.includes('pr√©sid√©e par') || l.includes('professeur') || l.includes('facult√©') ||
            l.includes('table des mati√®res') || l.includes('contents') ||
            l.includes('texte √©tabli') || l.includes('cat√©gorie') || l.includes('category') ||
            l.includes('voir aussi') || l.includes('see also') || l.includes('modifier') ||
            l.includes('mw-page-title') || l.includes('span class') ||
            line.length < 3 || (line.startsWith('(') && line.endsWith(')'))) {
            start = i + 1;
        } else if (line.length > 40) break;
    }
    text = lines.slice(start).join('\n').trim();

    return text;
}

function detectAuthor(parsed) {
    if (!parsed) return null;

    const links = parsed.links || [];
    const authorPrefixes = ['Auteur:', 'Author:', 'Autor:', 'Autore:', '‰ΩúËÄÖ:'];
    for (const link of links) {
        const linkTitle = link['*'] || '';
        for (const prefix of authorPrefixes) {
            if (linkTitle.startsWith(prefix)) {
                const authorName = linkTitle.replace(prefix, '').replace(/_/g, ' ').trim();
                if (authorName.length > 2 && authorName.length < 50) return authorName;
            }
        }
    }

    const categories = parsed.categories || [];
    for (const cat of categories) {
        const catName = cat['*'] || '';
        const authorMatch = catName.match(/(?:Textes|Po√®mes|≈íuvres|Works|Texts|Poems|Werke|Opere|Obras)\s+(?:de|by|von|di)\s+(.+)/i);
        if (authorMatch && authorMatch[1].length > 2 && authorMatch[1].length < 50) {
            return authorMatch[1].trim();
        }
    }

    const html = parsed.text?.['*'] || '';
    const classMatch = html.match(/<[^>]*class="[^"]*(?:ws-author|author|auteur|auteur-oeuvre)[^"]*"[^>]*>([^<]+)/i);
    if (classMatch) {
        const authorText = classMatch[1].trim();
        if (authorText.length > 2 && authorText.length < 50) return authorText;
    }

    const hrefMatch = html.match(/href="[^"]*(?:Auteur|Author|Autor|Autore):([^"&?#]+)"/i);
    if (hrefMatch) {
        return decodeURIComponent(hrefMatch[1]).replace(/_/g, ' ').trim();
    }

    const rawText = html.replace(/<[^>]+>/g, ' ').substring(0, 500);
    const parMatch = rawText.match(/(?:^|\n)\s*(?:par|de|by)\s+([A-Z√Ä-√ú][a-z√†-√º]+(?:\s+(?:de\s+)?[A-Z√Ä-√ú][a-z√†-√º\-]+){0,3})\s*(?:\n|$)/m);
    if (parMatch && parMatch[1].length > 3 && parMatch[1].length < 40) {
        return parMatch[1].trim();
    }

    const title = parsed.displaytitle || parsed.title || '';
    const cleanTitle = title.replace(/<[^>]+>/g, '');
    const parenthMatch = cleanTitle.match(/\(([^)]+)\)$/);
    if (parenthMatch) {
        const potentialAuthor = parenthMatch[1].trim();
        if (/^[A-Z√Ä-√ú][a-z√†-√º]+(\s+[A-Z√Ä-√ú][a-z√†-√º]+)*$/.test(potentialAuthor)) {
            return potentialAuthor;
        }
    }

    const dashMatch = cleanTitle.match(/^([^‚Äî‚Äì\-]+)[‚Äî‚Äì\-](.+)$/);
    if (dashMatch) {
        const part1 = dashMatch[1].trim();
        const part2 = dashMatch[2].trim();
        if (/^[A-Z√Ä-√ú][a-z√†-√º]+(\s+[A-Z√Ä-√ú][a-z√†-√º]+)*$/.test(part1)) return part1;
        if (/^[A-Z√Ä-√ú][a-z√†-√º]+(\s+[A-Z√Ä-√ú][a-z√†-√º]+)*$/.test(part2)) return part2;
    }

    const slashParts = cleanTitle.split('/');
    if (slashParts.length >= 2) return slashParts[0].trim();

    return null;
}

function isGoodTitle(title) {
    if (!title || title.length < 3 || title.length > 200) return false;
    const t = title.toLowerCase();

    if (/^(cat√©gor|category|kategorie|categoria)/i.test(t)) return false;
    if (/^(help|aide|hilfe|aiuto|ayuda|ajuda|manual|project|projet|image|file|fichier|template|mod√®le|module|media|special|sp√©cial):/i.test(t)) return false;
    if (/^(auteur|author|autor|autore):/i.test(t)) return false;
    if (/^(discussion|talk|diskussion|discussione):/i.test(t)) return false;
    if (/^(index|page|file|portail|portal|wiki):/i.test(t)) return false;

    if (/^list[ea]?\s+(de|of|di|von)/i.test(t)) return false;
    if (t.startsWith('index ') || t.endsWith(' index')) return false;
    if (t.includes('table des mati√®res') || t.includes('table of contents') || t.includes('inhaltsverzeichnis')) return false;
    if (t.includes('bibliographie') || t.includes('bibliography')) return false;

    // Rejeter dictionnaires, encyclop√©dies, annales, recueils de lois, etc.
    if (/dictionnaire|dictionary|w√∂rterbuch|dizionario|diccionario/i.test(t)) return false;
    if (/encyclop[a√¶]edi|encyclop√©die/i.test(t)) return false;
    if (/^annales\b|^grand dictionnaire|^recueil des/i.test(t)) return false;
    if (/inventaire raisonn√©|r√©pertoire|lexique|glossaire|lexicon|glossary/i.test(t)) return false;

    if (t.includes('sa vie et son ≈ìuvre') || t.includes('sa vie et son oeuvre')) return false;
    if (t.includes('his life and work') || t.includes('sein leben')) return false;
    if (t.includes('√©tude biographique') || t.includes('√©tude sur')) return false;
    if (t.includes('biographical study') || t.includes('biography of')) return false;
    if (/\bbiograph/i.test(t) && !t.includes('/')) return false;

    if ((t.includes('≈ìuvres compl√®tes') || t.includes('complete works') ||
        t.includes('gesammelte werke') || t.includes('opere complete')) && !t.includes('/')) return false;

    if (/(sommaire|contents|table des mati√®res)$/i.test(t)) return false;

    return true;
}

function isContentGoodQuality(text, parsed) {
    if (!text || text.length < 200) return { isGood: false, reason: 'too_short' };
    if (text.length > 80000) return { isGood: false, reason: 'too_long' };

    const html = parsed?.text?.['*'] || '';
    if (html.includes('redirectMsg') || html.includes('propose plusieurs √©ditions') ||
        html.includes('Cette page r√©pertorie')) return { isGood: false, reason: 'index' };

    const links = parsed?.links || [];
    const linkCharsEstimate = links.length * 30;
    if (text.length > 0 && linkCharsEstimate / text.length > 0.25) return { isGood: false, reason: 'link_density' };

    const lines = text.split('\n').filter(l => l.trim().length > 0);
    if (lines.length < 2) return { isGood: false, reason: 'too_short' };
    const avgLineLength = text.length / lines.length;

    if (avgLineLength < 60) {
        const withPunct = lines.filter(l => /[.!?‚Ä¶:;]$/.test(l.trim())).length;
        const punctRatio = withPunct / lines.length;
        if (punctRatio < 0.3) return { isGood: false, reason: 'listy' };
    }

    const title = (parsed.displaytitle || parsed.title || '').toLowerCase();
    const badWords = ['sommaire', 'contents', 'inhalt', 'table', 'index', 'chapitres', 'chapters'];
    if (badWords.some(w => title.includes(w))) return { isGood: false, reason: 'title_blacklist' };

    const archaicMarkers = /\b(chevalch|comande|ne¬∑l|oi√´l|mult\b|\bert\b|\bfant\b|\b√ßo\b|\bki\b|destr|guerpir|chalcier|seignurs|vassal[sz]|\bcuntre\b|\bpuis\b que|\bnuls\b hom)/i;
    const sample = text.substring(0, 500);
    const archaicHits = (sample.match(archaicMarkers) || []).length;
    if (archaicHits > 0) {
        const deepMarkers = sample.match(/\b(ert|fant|mult|comand[ea]|chevalch|oi√´l|guerpir|\b√ßo\b|\bki\b|seignurs)\b/gi);
        if (deepMarkers && deepMarkers.length >= 2) return { isGood: false, reason: 'archaic' };
    }

    return { isGood: true };
}

function detectIndexAndSubLink(parsed) {
    const html = parsed?.text?.['*'] || '';

    const isRedirect = html.includes('redirectMsg');
    const hasEditions = html.includes('propose plusieurs √©ditions') ||
                        html.includes('Cette page r√©pertorie');
    const isIndex = isRedirect || hasEditions;

    let subLink = null;
    if (isIndex) {
        const linkRegex = /href="\/wiki\/([^"]+)"/g;
        let match;
        while ((match = linkRegex.exec(html)) !== null) {
            const name = decodeURIComponent(match[1]);
            if (name.includes(':') || name.includes('Auteur') || name.includes('Discussion')) continue;
            if (name.includes('/') && !name.endsWith('/')) {
                if (!name.includes('Pr√©face') && !name.includes('Notice') &&
                    !name.includes('Table') && !name.includes('Index')) {
                    subLink = name;
                    break;
                }
            }
        }
    }
    return { isIndex, subLink };
}

function extractBestQuote(text) {
    if (!text || text.length < 80) return null;

    const paragraphs = text.split(/\n\n+/)
        .map(p => p.trim())
        .filter(p => p.length > 20)
        .filter(p => !/^\s*[IVXLCDM]{2,10}\b/.test(p))
        .filter(p => !/^\s*(CHAPTER|CHAPITRE|CANTO|LIVRE|BOOK)\s/i.test(p))
        .filter(p => !(p.length < 60 && /^[A-Z√Ä-√ú\s\-']+$/.test(p)))
        .filter(p => (p.match(/\d+/g) || []).length < p.split(' ').length * 0.3);

    if (paragraphs.length === 0) return null;

    const ideal = paragraphs.filter(p => {
        const len = p.trim().length;
        return len >= 100 && len <= 450;
    });
    if (ideal.length > 0) {
        return ideal[Math.floor(Math.random() * ideal.length)].trim();
    }

    const good = paragraphs.filter(p => {
        const len = p.trim().length;
        return len >= 80 && len <= 500;
    });
    if (good.length > 0) {
        return good[Math.floor(Math.random() * good.length)].trim();
    }

    for (const p of paragraphs) {
        const trimmed = p.trim();
        if (trimmed.length >= 60) {
            if (trimmed.length <= 500) return trimmed;
            const cut = trimmed.substring(0, 500);
            const lastSentence = Math.max(
                cut.lastIndexOf('. '), cut.lastIndexOf('.\n'),
                cut.lastIndexOf('! '), cut.lastIndexOf('? '),
                cut.lastIndexOf('‚Ä¶')
            );
            if (lastSentence > 200) return cut.substring(0, lastSentence + 1);
            const lastSpace = cut.lastIndexOf(' ');
            if (lastSpace > 300) return cut.substring(0, lastSpace) + '‚Ä¶';
            return cut + '‚Ä¶';
        }
    }
    return null;
}

async function fetchTextFromPage(ws, title, depth = 0) {
    if (depth > 4) return null;
    if (!isGoodTitle(title)) return null;

    console.log(`${'    '.repeat(depth + 1)}Parsing: ${title} (depth ${depth})`);
    const parsed = await parsePage(ws, title);
    if (!parsed?.text?.['*']) return null;

    const html = parsed.text['*'];
    const links = parsed.links || [];

    const basePage = title.split('/')[0];
    const subPageLinks = links.filter(l => {
        const t = l['*'] || '';
        return t.startsWith(basePage + '/') && l.ns === 0;
    });

    if (subPageLinks.length >= 5) {
        const randomSub = subPageLinks[Math.floor(Math.random() * subPageLinks.length)];
        console.log(`${'    '.repeat(depth + 1)}‚Ü≥ Sommaire d√©tect√© (${subPageLinks.length} sous-pages), suit: ${randomSub['*']}`);
        return await fetchTextFromPage(ws, randomSub['*'], depth + 1);
    }

    const { isIndex, subLink } = detectIndexAndSubLink(parsed);
    if (isIndex && subLink) {
        console.log(`${'    '.repeat(depth + 1)}‚Ü≥ Index d√©tect√©, suit: ${subLink}`);
        return await fetchTextFromPage(ws, subLink, depth + 1);
    }

    const text = extractText(html);
    if (text.length < 100) return null;

    const quality = isContentGoodQuality(text, parsed);
    if (!quality.isGood) {
        if (quality.reason === 'link_density' || quality.reason === 'listy') {
            const contentLinks = links.filter(l => l.ns === 0 && !(l['*'] || '').includes(':'));
            if (contentLinks.length > 0) {
                const randomLink = contentLinks[Math.floor(Math.random() * contentLinks.length)];
                console.log(`${'    '.repeat(depth + 1)}‚Ü≥ Contenu ${quality.reason}, suit lien: ${randomLink['*']}`);
                return await fetchTextFromPage(ws, randomLink['*'], depth + 1);
            }
        }
        return null;
    }

    const quote = extractBestQuote(text);
    if (!quote) return null;

    const author = detectAuthor(parsed);
    const cleanTitle = (parsed.displaytitle || title).replace(/<[^>]+>/g, '').replace(/&nbsp;/g, ' ').replace(/&amp;/g, '&').trim();

    if (!author) {
        console.log(`${'    '.repeat(depth + 1)}‚úó No author found for: ${cleanTitle}`);
        return null;
    }

    if (!isQuotePostWorthy(quote, author)) {
        console.log(`${'    '.repeat(depth + 1)}‚úó Post not worthy: "${quote.substring(0, 50)}‚Ä¶" by ${author}`);
        return null;
    }

    console.log(`${'    '.repeat(depth + 1)}‚úì Found: "${quote.substring(0, 60)}‚Ä¶" by ${author}`);
    return {
        text: quote,
        author,
        title: cleanTitle,
        lang: ws.lang,
        source: `${ws.url}/wiki/${encodeURIComponent(title)}`
    };
}

async function fetchQuoteFromWikisource(maxRetries = 25, forceLang = null, excludeUrls = new Set()) {
    for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
            const ws = pickWeightedLang(forceLang);
            console.log(`  Tentative ${attempt + 1}: ${ws.lang}.wikisource.org`);

            const pages = Math.random() < 0.5
                ? await getRandomPages(ws)
                : await searchWikisource(ws);

            if (!pages.length) continue;

            const shuffled = pages.sort(() => Math.random() - 0.5);

            for (const page of shuffled) {
                const result = await fetchTextFromPage(ws, page.title, 0);
                if (result && excludeUrls.has(result.source)) {
                    console.log(`    ‚ö†Ô∏è Already posted: ${result.source}, skipping`);
                    continue;
                }
                if (result) return result;
            }
        } catch (err) {
            console.log(`    ‚úó Error: ${err.message}`);
        }
    }
    return null;
}

// ‚îÄ‚îÄ‚îÄ PoetryDB Fallback (always reliable) ‚îÄ‚îÄ‚îÄ

/**
 * Fetch a random poem from PoetryDB (English poetry, always works).
 * This is the same source the app uses and never fails.
 */
async function fetchPoetryDBQuote() {
    try {
        // Get a random poem from PoetryDB
        const data = await httpGet('https://poetrydb.org/random/5');
        if (!Array.isArray(data) || data.length === 0) return null;

        for (const poem of data) {
            if (!poem.lines || !poem.author || poem.author === 'Unknown') continue;
            const text = poem.lines.join('\n').trim();
            if (text.length < 40 || text.length > 2000) continue;

            // Extract a good quote (100-450 chars ideal)
            let quote = text;
            if (quote.length > 450) {
                // Take first stanza or first ~400 chars
                const stanzaEnd = quote.indexOf('\n\n');
                if (stanzaEnd > 80 && stanzaEnd < 450) {
                    quote = quote.substring(0, stanzaEnd);
                } else {
                    quote = quote.substring(0, 400);
                    const lastLine = quote.lastIndexOf('\n');
                    if (lastLine > 200) quote = quote.substring(0, lastLine);
                    else quote += '‚Ä¶';
                }
            }

            if (quote.length < 40) continue;
            if (!isQuotePostWorthy(quote, poem.author)) continue;

            console.log(`   ‚úÖ PoetryDB: "${quote.substring(0, 60)}‚Ä¶" by ${poem.author}`);
            return {
                text: quote.trim(),
                author: poem.author,
                title: poem.title || 'Poetry',
                lang: 'en',
                source: `https://poetrydb.org`,
                fromTrending: false,
            };
        }
        return null;
    } catch (err) {
        console.log(`   ‚ö†Ô∏è PoetryDB fallback failed: ${err.message}`);
        return null;
    }
}

// ‚îÄ‚îÄ‚îÄ Mastodon API ‚îÄ‚îÄ‚îÄ

/**
 * V√©rifie les credentials Mastodon (GET /api/v1/accounts/verify_credentials).
 */
async function mastodonVerify(instance, accessToken) {
    const url = new URL(`https://${instance}/api/v1/accounts/verify_credentials`);
    return new Promise((resolve, reject) => {
        https.get(url.href, {
            headers: {
                'Authorization': `Bearer ${accessToken}`,
                'User-Agent': 'PalimpsestBot/1.0 (https://palimpseste.vercel.app)',
            }
        }, (res) => {
            let data = '';
            res.on('data', chunk => data += chunk);
            res.on('end', () => {
                try {
                    const parsed = JSON.parse(data);
                    if (res.statusCode >= 200 && res.statusCode < 300) resolve(parsed);
                    else reject(new Error(`Mastodon verify ${res.statusCode}: ${JSON.stringify(parsed)}`));
                } catch (e) {
                    reject(new Error(`Mastodon verify ${res.statusCode}: ${data}`));
                }
            });
        }).on('error', reject);
    });
}

/**
 * Poste un statut sur Mastodon (POST /api/v1/statuses).
 * @param {string} instance - Le domaine de l'instance (ex: mastodon.social)
 * @param {string} accessToken - Le token d'acc√®s
 * @param {string} statusText - Le texte du toot
 * @param {string} lang - Code langue ISO 639-1
 */
async function postToMastodon(instance, accessToken, statusText, lang) {
    const body = JSON.stringify({
        status: statusText,
        visibility: 'public',
        language: lang || 'fr',
    });

    return httpRequest({
        hostname: instance,
        path: '/api/v1/statuses',
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${accessToken}`,
            'Content-Type': 'application/json',
            'Content-Length': Buffer.byteLength(body),
            'User-Agent': 'PalimpsestBot/1.0 (https://palimpseste.vercel.app)',
        }
    }, body);
}

// ‚îÄ‚îÄ‚îÄ Hashtags dynamiques bas√©s sur le contenu ‚îÄ‚îÄ‚îÄ

/**
 * Cat√©gories de mots-cl√©s pour d√©tecter le th√®me du texte.
 * Inspir√© du Kal√©idoscope de l'app (exploration.js).
 */
const CONTENT_TAGS = {
    // Formes litt√©raires
    poetry:    { hashtag: 'poetry',    keywords: ['po√©sie', 'po√®me', 'vers', 'rime', 'strophe', 'sonnet', 'ode', '√©l√©gie', 'ballade', 'hymne', 'poem', 'verse', 'rhyme', 'lyric'] },
    novel:     { hashtag: 'novel',     keywords: ['roman', 'chapitre', 'novel', 'chapter', 'fiction', 'r√©cit', 'histoire', 'narration'] },
    theatre:   { hashtag: 'theatre',   keywords: ['th√©√¢tre', 'sc√®ne', 'acte', 'trag√©die', 'com√©die', 'drame', 'theater', 'play', 'scene', 'act', 'tragedy', 'comedy'] },
    philosophy:{ hashtag: 'philosophy',keywords: ['philosophie', 'pens√©e', 'r√©flexion', 'sagesse', 'raison', 'v√©rit√©', 'philosophy', 'wisdom', 'truth', 'reason'] },
    fable:     { hashtag: 'fable',     keywords: ['fable', 'conte', 'morale', 'il √©tait une fois', 'tale', 'once upon', 'fairy'] },
    essay:     { hashtag: 'essay',     keywords: ['essai', 'm√©ditation', 'discours', 'essay', 'discourse', 'speech'] },
    // Tonalit√©s / Ambiances
    love:      { hashtag: 'love',      keywords: ['amour', 'c≈ìur', '√¢me', 'passion', 'd√©sir', 'baiser', 'love', 'heart', 'soul', 'desire', 'kiss', 'beloved'] },
    melancholy:{ hashtag: 'melancholy',keywords: ['spleen', 'm√©lancolie', 'tristesse', 'solitude', 'nostalgie', 'regret', 'melancholy', 'sorrow', 'loneliness'] },
    nature:    { hashtag: 'nature',    keywords: ['nature', 'fleur', 'arbre', 'mer', 'ciel', 'soleil', 'lune', '√©toile', 'flower', 'tree', 'sea', 'sky', 'sun', 'moon', 'star', 'forest', 'river'] },
    gothic:    { hashtag: 'gothic',    keywords: ['fant√¥me', 'spectre', 't√©n√®bres', 'terreur', 'nuit', 'mort', 'ombre', 'ghost', 'shadow', 'darkness', 'terror', 'death'] },
    epic:      { hashtag: 'epic',      keywords: ['h√©ros', 'bataille', 'gloire', 'honneur', 'guerre', 'conqu√™te', 'hero', 'battle', 'glory', 'honor', 'war', 'sword'] },
    mystic:    { hashtag: 'mystic',    keywords: ['divin', 'extase', 'sacr√©', '√©ternel', 'lumi√®re', 'pri√®re', 'divine', 'sacred', 'eternal', 'prayer', 'spirit'] },
    dream:     { hashtag: 'dream',     keywords: ['r√™ve', 'songe', 'vision', 'sommeil', 'chim√®re', 'illusion', 'dream', 'vision', 'sleep', 'reverie'] },
    humor:     { hashtag: 'humor',     keywords: ['rire', 'comique', 'ironie', 'satire', 'moquerie', 'ridicule', 'laugh', 'irony', 'satire', 'wit', 'comedy'] },
    // √âpoques / Courants
    romanticism:{ hashtag: 'romanticism', keywords: ['romantisme', 'romantique', 'sublime', 'romantic', 'sublime'] },
    classics:  { hashtag: 'classics',     keywords: ['antique', 'olympe', 'mythologie', 'latin', 'grec', 'classic', 'ancient', 'mythology', 'greek', 'roman'] },
};

/**
 * Hashtags communautaires Mastodon (fixes, adapt√©s √† la langue).
 * #Bookstodon ‚Äî communaut√© anglophone la plus active sur le Fediverse
 * #MastoLivre ‚Äî communaut√© francophone livres
 * #books #literature ‚Äî universels, tr√®s suivis
 */
const PLATFORM_TAGS_BY_LANG = {
    fr: ['#bookstodon', '#mastolivre', '#litterature'],
    en: ['#bookstodon', '#books', '#literature'],
    de: ['#bookstodon', '#books', '#literatur'],
    it: ['#bookstodon', '#books', '#letteratura'],
    es: ['#bookstodon', '#books', '#literatura'],
    pt: ['#bookstodon', '#books', '#literatura'],
};
const PLATFORM_TAGS_DEFAULT = ['#bookstodon', '#books', '#literature'];

/**
 * Analyse le texte et retourne les meilleurs hashtags dynamiques.
 * @param {string} text - Le texte de l'extrait
 * @param {string} lang - La langue de l'extrait
 * @param {number} max - Nombre max de hashtags de contenu (d√©faut: 3)
 * @returns {string} Hashtags format√©s
 */
function buildDynamicHashtags(text, lang, max = 3) {
    const lower = (text || '').toLowerCase();
    const scores = {};

    for (const [cat, { keywords }] of Object.entries(CONTENT_TAGS)) {
        let score = 0;
        for (const kw of keywords) {
            // Utiliser des limites de mots pour √©viter les faux positifs
            // (ex: "wit" ne doit pas matcher dans "with")
            const regex = new RegExp(`\\b${kw.toLowerCase().replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}\\b`, 'i');
            if (regex.test(lower)) score++;
        }
        if (score > 0) scores[cat] = score;
    }

    const top = Object.entries(scores)
        .sort((a, b) => b[1] - a[1])
        .slice(0, max)
        .map(([cat]) => `#${CONTENT_TAGS[cat].hashtag}`);

    if (top.length === 0) {
        top.push('#lit');
    }

    const platformTags = PLATFORM_TAGS_BY_LANG[lang] || PLATFORM_TAGS_DEFAULT;
    return [...top, ...platformTags].join(' ');
}

// ‚îÄ‚îÄ‚îÄ Format Post ‚îÄ‚îÄ‚îÄ

/**
 * Mastodon a une limite de 500 caract√®res par d√©faut (varie selon l'instance).
 * On utilise 500 comme standard.
 * 
 * Lien intelligent :
 *   - Si extraitId ‚Üí lien direct #text/{id}
 *   - Sinon ‚Üí lien #preview?t=snippet&a=auteur&s=source
 *     (l'app affiche une carte de pr√©visualisation avec le texte)
 */
function formatPost(quote) {
    const maxChars = 500;

    const lang = quote.lang || 'fr';

    // Construire le lien intelligent
    let appLink;
    if (quote.extraitId) {
        appLink = `\nhttps://palimpseste.vercel.app/#text/${quote.extraitId}`;
    } else {
        const snippet = (quote.text || '').substring(0, 80).trim();
        const params = new URLSearchParams({
            t: snippet,
            a: quote.author || 'Anonyme',
        });
        if (quote.source) params.set('s', quote.source);
        appLink = `\nhttps://palimpseste.vercel.app/#preview?${params.toString()}`;
    }

    const hashtags = buildDynamicHashtags(quote.text, lang, 3);
    const hashtagLine = `\n${hashtags}`;
    const suffix = `\n\n‚Äî ${quote.author}${appLink}${hashtagLine}`;

    let text = quote.text;
    const available = maxChars - suffix.length - 1;

    if (text.length > available) {
        text = text.substring(0, available);
        const lastSpace = text.lastIndexOf(' ');
        if (lastSpace > text.length * 0.6) {
            text = text.substring(0, lastSpace);
        }
        text += '‚Ä¶';
    }

    return `${text}\n\n‚Äî ${quote.author}${appLink}${hashtagLine}`;
}

// ‚îÄ‚îÄ‚îÄ Main ‚îÄ‚îÄ‚îÄ

async function main() {
    const instance = process.env.MASTODON_INSTANCE;
    const accessToken = process.env.MASTODON_ACCESS_TOKEN;
    const langArg = process.argv.find(a => a.startsWith('--lang='));
    const forceLang = langArg ? langArg.split('=')[1] : null;

    if (!instance || !accessToken) {
        console.error('‚ùå Missing Mastodon credentials in environment variables');
        console.error('   Required: MASTODON_INSTANCE, MASTODON_ACCESS_TOKEN');
        console.error('   Example:  MASTODON_INSTANCE=mastodon.social');
        console.error('   Generate token: Preferences > Development > New Application');
        process.exit(1);
    }

    let quote = null;

    // 0) Charger l'historique des posts du bot pour √©viter les doublons
    console.log('üìã Loading bot post history‚Ä¶');
    const excludeUrls = await fetchRecentBotPosts();

    // 1) Essayer d'abord les tendances Supabase
    console.log(`üî• Fetching trending quote from Supabase${forceLang ? ` (lang: ${forceLang})` : ''}‚Ä¶`);
    quote = await fetchTrendingQuote(forceLang, excludeUrls);

    if (quote) {
        console.log(`   ‚úÖ Got trending quote by ${quote.author} (${quote.lang})`);
    } else {
        // 2) Fallback: Wikisource live (25 retries)
        console.log(`\nüîç Fallback: fetching from Wikisource${forceLang ? ` (lang: ${forceLang})` : ''}‚Ä¶\n`);
        quote = await fetchQuoteFromWikisource(25, forceLang, excludeUrls);
    }

    // 3) Ultimate fallback: PoetryDB (en anglais, toujours fiable)
    if (!quote) {
        console.log('\nüé≠ Ultimate fallback: fetching from PoetryDB‚Ä¶');
        quote = await fetchPoetryDBQuote();
    }

    // 4) Relaxed mode: re-allow previously posted if nothing else works
    if (!quote) {
        console.log('\n‚ôªÔ∏è Relaxed mode: retrying Wikisource without dedup filter‚Ä¶');
        quote = await fetchQuoteFromWikisource(25, forceLang, new Set());
    }

    if (!quote) {
        console.error('‚ùå Could not find a suitable quote from any source');
        process.exit(1);
    }

    // 3) Sauvegarder dans Supabase (pour le lien ET pour le tracking anti-doublon)
    if (!quote.extraitId) {
        console.log('\nüíæ Saving Wikisource extract to Supabase‚Ä¶');
        const savedId = await saveExtraitToSupabase(quote);
        if (savedId) {
            quote.extraitId = savedId;
            console.log(`   ‚úÖ Extract saved, link will use #text/${savedId}`);
        } else {
            console.log('   ‚ö†Ô∏è Could not save, link will use #preview fallback');
        }
    } else {
        // Trending quote : sauvegarder aussi pour le tracking (√©viter repost)
        console.log('\nüíæ Saving trending extract reference for dedup tracking‚Ä¶');
        await saveExtraitToSupabase(quote);
    }

    const post = formatPost(quote);

    console.log(`\nüìù Posting to Mastodon @${instance} (${post.length} chars, lang: ${quote.lang}, source: ${quote.fromTrending ? 'TRENDING' : 'WIKISOURCE'}):\n${post}\n`);
    console.log(`üìñ Source: ${quote.source}\n`);

    try {
        console.log(`üîê Verifying Mastodon credentials on ${instance}‚Ä¶`);
        const account = await mastodonVerify(instance, accessToken);
        console.log(`   Logged in as @${account.username}@${instance}`);

        const result = await postToMastodon(instance, accessToken, post, quote.lang);
        console.log(`‚úÖ Posted to Mastodon!`);
        console.log(`   ${result.url}`);
    } catch (err) {
        console.error(`‚ùå Failed to post: ${err.message}`);
        process.exit(1);
    }
}

main();
